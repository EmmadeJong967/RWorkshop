---
title: "RStudio Workshop"
subtitle: "Statistical modelling in R"
author: Sebastian Rauschert
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  ioslides_presentation:
    template: assets/templates/ioslides.html
    logo: assets/images/logo800.jpg
    css: assets/css/ioslides.css
    widescreen: true
    incremental: true
vignette: >
  %\VignetteIndexEntry{Telethon Kids Institute markdown ioslides template}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r init, include = FALSE, echo = FALSE}
library(biometrics)
library(datasets)
library(knitr)
library(ggplot2)
library(gridExtra)
library(grid)
library(tidyverse)
library(ggpubr)
library(broom)
library(jtools)
library(tidyr)
library(ggfortify)
```

# Statistical Modelling in R

## Notes

order of included R functions:

>- <code style="color:tomato;">lm()</code>  
>- <code style="color:tomato;">summary()</code>  
>- <code style="color:tomato;">ggplot() + statqq()</code>  
>- <code style="color:tomato;">ggplot() + geom_smooth()</code>  
>- <code style="color:tomato;">tidy(), augment(), glance()</code>  
>- <code style="color:tomato;">summ(), plot_summs()</code>  
>- <code style="color:tomato;">autoplot()</code>  
>- <code style="color:tomato;">glm() (different families)</code>  
>- <code style="color:tomato;">lmer()</code>

## What we cover

>- Linear Regression
>- Multiple Linear Regression 
>- Generalized Linear Models
>- Briefly: Mixed effects model
```{r echo=FALSE, error=FALSE, message=FALSE, warning=FALSE, out.extra = 'class="centre" style="width: 500px;"', warnings=FALSE}
setwd("/Users/srauschert/Desktop/Work/20.) Git_GitHub/RWorkshop/")
tki_demo <- read_csv("data/demo.csv")
tki_demo %>%
  filter(day2 < 100) %>%
  
ggplot( aes(day2, day3)) +
  labs(title = "TKI Dataset", x = "day1", y = "day2") +
  geom_point(size = 4) +
  geom_smooth(method = 'lm')+
  scale_color_telethonkids("light") +
  theme_minimal()
```

# Linear Regression

## Linear Regression in R 

In a linear regression, we aim to find a model: <br/> 

>- that represents our data and 
>- can give information about the association between our variables of interest.
The command in R for a linear model is <br/>
  
  <code style="aligne:center; color:tomato;">lm(y ~ x, data = data)</code>.

This is called the _formula notation_ in R. 

## ! Tip in the tidyverse

>- The formula-type code with the data assignment at the end might seem non-tidy.
>- But, we can use the pipe <code style="color:tomato;">%>%</code> in the following way:
<code style="color:tomato;">data %>%  
      lm(y ~ x, data = .)</code>  
    
>- with the "." we assign the data in the pipe

# Before we model 

## Data set summary
Let's first have a look at the summary table of the example data set, by using the <code style="color:tomato;">summary()</code> command:

```{r, echo = FALSE, out.extra = 'class="centre" style="width: 100px;"',warning=FALSE}
#kable(summary(tki_demo[,c(6:8)]))
summary(tki_demo[,c(6:8)])
```

# Visualisation of data distributions

## Helpful plots before modelling
Before we start with the linear regression model, we need to get an idea of the underlying data and its distribution.
We know that the linear regression has the assumtptions:

>- Linear relationship
>- Multivariate normality
>- No or little multicollinearity
>- No auto-correlation
>- Homoscedasticity

## QQ-plot: {.smaller}
```{r, echo=TRUE, out.extra = 'class="centre" style="width: 700px;"', warning=FALSE}
tki_demo %>%
  gather(Days, measurement, day1:day3, factor_key = TRUE) %>%
  ggplot( aes(sample = measurement, color=Days)) + stat_qq() + facet_wrap(~Days)
```


## Boxplots to check for outliers
```{r echo = FALSE, out.extra = 'class="centre" style="width: 700px;"',warning=FALSE}
with_out <- tki_demo %>%
  #filter(day2 < 100) %>%
  gather(Days, measurement, day1:day3, factor_key = TRUE) %>%
  ggplot(aes(y = measurement,x = Days, fill = Days)) +
  labs(title = "Days: 1 to 3 with outlier", x = "", y = "Measurment") +
  geom_boxplot() +
  scale_color_telethonkids("light") +
  theme_minimal()
no_out <- tki_demo %>%
  filter(day2 < 100) %>%
  gather(Days, measurement, day1:day3, factor_key=TRUE) %>%
  ggplot(aes(y = measurement,x = Days, fill = Days)) +
  labs(title = "Days: 1 to 3 outlier removed", x = "", y = "Measurment") +
  geom_boxplot() +
  scale_color_telethonkids("light") +
  theme_minimal()
ggarrange(with_out, no_out, ncol = 2, common.legend = TRUE, legend = FALSE )
```


## Plot the variables

```{r, echo = FALSE, out.extra = 'class="centre" style="width: 700px;"',warning=FALSE}
plot1 <- 
  tki_demo %>%
  filter(day2 < 100) %>%
  ggplot( aes(day1, day2)) +
  labs(title = "Day's 1 and 2", x = "Day 1", y = "Day 2") +
  geom_point(size = 4) +
  geom_smooth(method = 'lm')+
  scale_color_telethonkids("light") +
  theme_minimal()
plot2 <- 
 tki_demo %>%
  filter(day2 < 100) %>%
  ggplot(aes(day2, day3)) +
  labs(title = "Day's 2 and 3", x = "Day 2", y = "Day 3") +
  geom_point(size = 4) +
  geom_smooth(method = 'lm')+
  scale_color_telethonkids("light") +
  theme_minimal()
plot3 <- ggplot(tki_demo, aes(day1, day3)) +
  labs(title = "Day's 1 and 3", x = "Day 1", y = "Day 3") +
  geom_point(size = 4) +
  geom_smooth(method = 'lm')+
  scale_color_telethonkids("light") +
  theme_minimal()
grid.arrange(plot1, plot2, plot3, nrow = 2, ncol = 2)
```

# Linear Regression

## The <code style="color:tomato;">lm()</code> function

In the plots, we could already see, that <em>day 2</em> and <em>day 3</em> seem to be associated. This is obvious when drawing a line in the plot.
Let's now perform a linear regression model in R.

<code style="color:tomato;">lm(day2 ~ day3, data = tki_demo)</code>

- As said before, the first argument in the code is **<em>y</em>**, our outcome variable or <em>dependent variable</em>. In this case it is **<em>day2</em>**.

- The second Argument is **<em>x</em>**, the <em>independent variable</em>. In our case: **<em>day3</em>**.

- We also specify the data set that holds the variables we specified as **<em>x</em>** and **<em>y</em>**.

## Linear Regression Results

Now we want to look at the results of the linear regression. So how do we get the <em>p-value</em> and <em>\(\beta\)-coefficient</em> for the association?

In R, we add the <code style="color:tomato;">summary()</code> function to the <code style="color:tomato;">lm()</code> function, like so:

<code style="color:tomato;">summary(lm(y ~ x, data = data))</code>

We can also store our model results in a variable:  
<code style="color:tomato;">model1 <- lm(y ~ x, data = data)</code>, and then use summary: <code style="color:tomato;">summary(model1)</code>

## Example Results {.smaller}

```{r, message=FALSE,  warning=FALSE, error=FALSE, echo = FALSE,out.extra = 'class="centre" style="width: 500px;"'}
#summary(lm(Petal.Length~Petal.Width, data=iris))
lm1 <- lm(day1 ~ day3, data = tki_demo)
library(sjPlot)
#tab_model(lm1, file="output.html")
summary(lm1)
```

# <code style="color:tomato;">jtools</code> and <code style="color:tomato;">broom</code>

## Improving the accessibility of the <code style="color:tomato;">lm()</code> results

>- The output before contains a lot of relevant information, but it is not straighforward to access the individual parameters like p-values and betas.
>- The <code style="color:tomato;">broom</code> R package is in line with the "tidy" data handling in R and turns the linear model results into an easy accessible tibble format:
```{r}
tidy(lm1)
```


## Improving output style {.smaller}

>- The <code style="color:tomato;">broom</code> package helps with the accessibility of the output, but the style of the output is not very appealing for a publiation or a report. 
>- The <code style="color:tomato;">jtools</code> package helps with this and has other nice functionalities such as forrest plots for coefficients and confidence intervals:
```{r results = 'asis'}
export_summs(lm1)
```


## Access more model info for diagnostics {.smaller}

```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
model <- lm(day2 ~ day3, data = tki_demo)
head(augment(model))
```


## Diagnostic Plots {.smaller}

```{r, echo=TRUE, warning=FALSE, error=FALSE}
autoplot(model)
```


<div align="center">
```{r eval=FALSE, include=FALSE}
ggplot(model.diag.metrics, aes(Petal.Length, Petal.Width)) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  geom_segment(aes(xend = Petal.Length, yend = .fitted), color = "red", size = 0.3)
```
</div>

# Multiple Linear Regression
## How to? {.smaller}
Multiple linear regression works with the same function in R :  
<code style="color:tomato;">lm(y ~ x + covar1 + covar2 + ... + covarx , data = data)</code>

```{r}
export_summs(lm(day3 ~ day2 + male, data = tki_demo))
```

## Example 1: one model {.smaller}
With the demo data set:
```{r}
export_summs(lm(day3 ~ day2 + male + smoker, data = tki_demo))
```

## Example 2: more models {.smaller}
With the demo data set:
```{r}
lm1 <- lm(day3 ~ day2, data = tki_demo)
lm2 <- lm(day3 ~ day2 + male + smoker, data = tki_demo)
export_summs(lm1, lm2)
```

## Forrest plot to compare coefficients in the model
>- Often we want to visualise the coefficients in the model to see their impact on the outcome, or visualise the coefficient of specific variable in two models, that differ only in the adjusted covariates. 
>- The <code style="color:tomato;">jtools</code> package has a nice function to do this very easily, utilising <code style="color:tomato;">ggplot2</code>:  
<code style="color:tomato;">plot_summs()</code>

## Example 1: one model

```{r}
plot_summs(lm1)
```

## Example 2: more models

```{r}
plot_summs(lm1, lm2)
```

## Example 3: compare specific coefficients

```{r}
plot_summs(lm1, lm2, coefs = "day2")
```


## Getting more info: Confidence Intervalls {.smaller}
>- With <code style="color:tomato;">jtools</code> we can access more information from the model in an easy step. 
>- Here, we access the confidence intervall and variance inflation factor (for multicollinearity testing), but leave out the p-values:
```{r}
summ(lm2, scale = TRUE, vifs = TRUE, part.corr = TRUE, 
     confint = TRUE, pvals = FALSE)$coeftable
```


# Generalized linear models

## Principles

>- The generalized linear model works very similar to the <code style="color:tomato;">lm()</code> function. We use the <code style="color:tomato;">glm()</code> function instead. 
>- The <code style="color:tomato;">lm()</code> function always assumes a linear distribution, whereas in the <code style="color:tomato;">glm()</code> function, we have to assign the distribution ("link") and a family type ourselves.  
>- For a logistic regression, we have to assign: <code style="color:tomato;">family = binomial(link = "logit")</code>
>- For a poisson regression, we assign: <code style="color:tomato;">family = poisson(link = "log")</code>    

## Code and output: Logistic regression {.smaller}

```{r}
export_summs(glm(smoker ~ male, data = tki_demo, family = binomial(link='logit')))
```

## Code and output: Poisson Regression {.smaller}

```{r}
export_summs(glm(smoker ~ male,data = tki_demo, family = poisson(link='log')))
```

# Linear mixed effects model

## The <code style="color:tomato;">lme4</code> package

When we want to also account for random effects or clusters such as intervention if the effect of this is not what we are interested in, or study center in the case of a multi-center study, we use the <code style="color:tomato;">lme4</code> package.

The formula works in the following way:  

>- <code style="color:tomato;">lmer(y ~ x + (1 + x | randomEffect), data = data) </code>, for random slope  
>- <code style="color:tomato;">lmer(y ~ x + (1 + x | randomEffect) + (1 | otherVariable), data = data)</code>, including <code style="color:tomato;">otherVariable</code> as a variable that has an impact on the slope 

## Example

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(lme4)
lmer(day1 ~ day2 + (1 + day2 | intervention), data = tki_demo )
```

# Extra: _Simple_ tests

## t-test, wilcoxon-test, chi-square-test

- t-test:
    - <code style="color:tomato;">t.test(datx, daty)</code> 


- wilcoxon test:
    - <code style="color:tomato;">wilcox.test(datx, daty)</code>
    
    
- chi-square-test:
    - <code style="color:tomato;">chisq.test(group1, group2)</code>

# Summary

## Models

- Linear regression and multiple linear regression both work by using <code style="color:tomato;">lm()</code>
- Models with for other distributions (e.g. logistic regression): 
    - <code style="color:tomato;">glm()</code>
    - specify <code style="color:tomato;">family</code> and
    - <code style="color:tomato;">link</code>
- Linear mixed effects model: <code style="color:tomato;">lmer()</code>

## Tidy results

- All models work with the <code style="color:tomato;">broom</code> and <code style="color:tomato;">jtools</code> packages
- tidy results: <code style="color:tomato;">tidy()</code>
- more results: e.g. <code style="color:tomato;">augment(), glance()</code>

## Publication ready

- With the <code style="color:tomato;">jtools</code> package
- <code style="color:tomato;">export_summs()</code> for regression table
- <code style="color:tomato;">plot_summs()</code> for forest plots



# The end of: modelling in R